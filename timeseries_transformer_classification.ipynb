{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset\n"
      ],
      "metadata": {
        "id": "zz306qGMDQp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(8)\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/612.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/612.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.2/612.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m604.2/612.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "metadata": {
        "id": "lOgpJMrHDQp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dd06be-3e25-432f-b3d4-db8c4339dd0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "telemetry = pd.read_csv('/content/drive/MyDrive/aitomatic/PdM_telemetry.csv')\n",
        "errors = pd.read_csv('/content/drive/MyDrive/aitomatic/PdM_errors.csv')\n",
        "maint = pd.read_csv('/content/drive/MyDrive/aitomatic/PdM_maint.csv')\n",
        "failures = pd.read_csv('/content/drive/MyDrive/aitomatic/PdM_failures.csv')\n",
        "machines = pd.read_csv('/content/drive/MyDrive/aitomatic/PdM_machines.csv')\n",
        "telemetry['datetime'] = pd.to_datetime(telemetry['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "errors['datetime'] = pd.to_datetime(errors['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "maint['datetime'] = pd.to_datetime(maint['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "failures['datetime'] = pd.to_datetime(failures['datetime'], format=\"%Y-%m-%d %H:%M:%S\")"
      ],
      "metadata": {
        "id": "d9Ke12DQ9I1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_count = pd.get_dummies(errors)\n",
        "features = telemetry.merge(error_count, on=['datetime', 'machineID'], how='left')\n",
        "# comp_rep = pd.get_dummies(maint)\n",
        "# features = features.merge(comp_rep, on=['datetime', 'machineID'], how='left')\n",
        "machines_m = pd.get_dummies(machines)\n",
        "features = features.merge(machines_m, on=['machineID'], how='left').fillna(0.0)\n",
        "features = features.groupby(['machineID','datetime']).max().reset_index()\n",
        "# features[\"hours\"] = features['datetime'].apply(lambda x: x.hour / 24)\n",
        "features = features.merge(failures, on=['datetime', 'machineID'], how='left').fillna('none')\n",
        "label2int = {\"none\":0,\"comp1\":1,\"comp2\":1,\"comp3\":1,\"comp4\":1}\n",
        "n_classes = len(label2int)\n",
        "features[\"failure\"] = features[\"failure\"].apply(lambda x: label2int[x])\n",
        "features"
      ],
      "metadata": {
        "id": "WsPX9XZZKLIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "b8f41765-a09d-418c-b777-8b08e0ec2678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        machineID            datetime        volt      rotate    pressure  \\\n",
              "0               1 2015-01-01 06:00:00  176.217853  418.504078  113.077935   \n",
              "1               1 2015-01-01 07:00:00  162.879223  402.747490   95.460525   \n",
              "2               1 2015-01-01 08:00:00  170.989902  527.349825   75.237905   \n",
              "3               1 2015-01-01 09:00:00  162.462833  346.149335  109.248561   \n",
              "4               1 2015-01-01 10:00:00  157.610021  435.376873  111.886648   \n",
              "...           ...                 ...         ...         ...         ...   \n",
              "876137        100 2016-01-01 02:00:00  179.438162  395.222827  102.290715   \n",
              "876138        100 2016-01-01 03:00:00  189.617555  446.207972   98.180607   \n",
              "876139        100 2016-01-01 04:00:00  192.483414  447.816524   94.132837   \n",
              "876140        100 2016-01-01 05:00:00  165.475310  413.771670  104.081073   \n",
              "876141        100 2016-01-01 06:00:00  171.336037  496.096870   79.095538   \n",
              "\n",
              "        vibration  errorID_error1  errorID_error2  errorID_error3  \\\n",
              "0       45.087686             0.0             0.0             0.0   \n",
              "1       43.413973             0.0             0.0             0.0   \n",
              "2       34.178847             0.0             0.0             0.0   \n",
              "3       41.122144             0.0             0.0             0.0   \n",
              "4       25.990511             0.0             0.0             0.0   \n",
              "...           ...             ...             ...             ...   \n",
              "876137  50.771941             0.0             0.0             0.0   \n",
              "876138  35.123072             0.0             0.0             0.0   \n",
              "876139  48.314561             0.0             0.0             0.0   \n",
              "876140  44.835259             0.0             0.0             0.0   \n",
              "876141  37.845245             0.0             0.0             0.0   \n",
              "\n",
              "        errorID_error4  errorID_error5  age  model_model1  model_model2  \\\n",
              "0                  0.0             0.0   18             0             0   \n",
              "1                  0.0             0.0   18             0             0   \n",
              "2                  0.0             0.0   18             0             0   \n",
              "3                  0.0             0.0   18             0             0   \n",
              "4                  0.0             0.0   18             0             0   \n",
              "...                ...             ...  ...           ...           ...   \n",
              "876137             0.0             0.0    5             0             0   \n",
              "876138             0.0             0.0    5             0             0   \n",
              "876139             0.0             0.0    5             0             0   \n",
              "876140             0.0             0.0    5             0             0   \n",
              "876141             0.0             0.0    5             0             0   \n",
              "\n",
              "        model_model3  model_model4  failure  \n",
              "0                  1             0        0  \n",
              "1                  1             0        0  \n",
              "2                  1             0        0  \n",
              "3                  1             0        0  \n",
              "4                  1             0        0  \n",
              "...              ...           ...      ...  \n",
              "876137             0             1        0  \n",
              "876138             0             1        0  \n",
              "876139             0             1        0  \n",
              "876140             0             1        0  \n",
              "876141             0             1        0  \n",
              "\n",
              "[876142 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-96f16cf7-4482-47f8-8247-98b7bfedaadb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>machineID</th>\n",
              "      <th>datetime</th>\n",
              "      <th>volt</th>\n",
              "      <th>rotate</th>\n",
              "      <th>pressure</th>\n",
              "      <th>vibration</th>\n",
              "      <th>errorID_error1</th>\n",
              "      <th>errorID_error2</th>\n",
              "      <th>errorID_error3</th>\n",
              "      <th>errorID_error4</th>\n",
              "      <th>errorID_error5</th>\n",
              "      <th>age</th>\n",
              "      <th>model_model1</th>\n",
              "      <th>model_model2</th>\n",
              "      <th>model_model3</th>\n",
              "      <th>model_model4</th>\n",
              "      <th>failure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 06:00:00</td>\n",
              "      <td>176.217853</td>\n",
              "      <td>418.504078</td>\n",
              "      <td>113.077935</td>\n",
              "      <td>45.087686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 07:00:00</td>\n",
              "      <td>162.879223</td>\n",
              "      <td>402.747490</td>\n",
              "      <td>95.460525</td>\n",
              "      <td>43.413973</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 08:00:00</td>\n",
              "      <td>170.989902</td>\n",
              "      <td>527.349825</td>\n",
              "      <td>75.237905</td>\n",
              "      <td>34.178847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 09:00:00</td>\n",
              "      <td>162.462833</td>\n",
              "      <td>346.149335</td>\n",
              "      <td>109.248561</td>\n",
              "      <td>41.122144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-01-01 10:00:00</td>\n",
              "      <td>157.610021</td>\n",
              "      <td>435.376873</td>\n",
              "      <td>111.886648</td>\n",
              "      <td>25.990511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876137</th>\n",
              "      <td>100</td>\n",
              "      <td>2016-01-01 02:00:00</td>\n",
              "      <td>179.438162</td>\n",
              "      <td>395.222827</td>\n",
              "      <td>102.290715</td>\n",
              "      <td>50.771941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876138</th>\n",
              "      <td>100</td>\n",
              "      <td>2016-01-01 03:00:00</td>\n",
              "      <td>189.617555</td>\n",
              "      <td>446.207972</td>\n",
              "      <td>98.180607</td>\n",
              "      <td>35.123072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876139</th>\n",
              "      <td>100</td>\n",
              "      <td>2016-01-01 04:00:00</td>\n",
              "      <td>192.483414</td>\n",
              "      <td>447.816524</td>\n",
              "      <td>94.132837</td>\n",
              "      <td>48.314561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876140</th>\n",
              "      <td>100</td>\n",
              "      <td>2016-01-01 05:00:00</td>\n",
              "      <td>165.475310</td>\n",
              "      <td>413.771670</td>\n",
              "      <td>104.081073</td>\n",
              "      <td>44.835259</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876141</th>\n",
              "      <td>100</td>\n",
              "      <td>2016-01-01 06:00:00</td>\n",
              "      <td>171.336037</td>\n",
              "      <td>496.096870</td>\n",
              "      <td>79.095538</td>\n",
              "      <td>37.845245</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>876142 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96f16cf7-4482-47f8-8247-98b7bfedaadb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f9903784-1f46-4099-9c7a-931bac91b3cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9903784-1f46-4099-9c7a-931bac91b3cb')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f9903784-1f46-4099-9c7a-931bac91b3cb button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96f16cf7-4482-47f8-8247-98b7bfedaadb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96f16cf7-4482-47f8-8247-98b7bfedaadb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split train test\n",
        "input_length = 24\n",
        "n_upsampling = 5\n",
        "hours = np.arange(input_length)\n",
        "Q1, Q2, Q3 = input_length// 4, input_length // 2, input_length*3//4\n",
        "milestone = '2015-10-20 01:00:00'\n",
        "train = features[features[\"datetime\"] < pd.to_datetime(milestone)]\n",
        "test = features[features[\"datetime\"] >= pd.to_datetime(milestone)]\n",
        "# train.drop(columns=[\"datetime\"],inplace=True)\n",
        "# test.drop(columns=[\"datetime\"],inplace=True)\n",
        "x_train,y_train = [], []\n",
        "x_test,y_test = [], []\n",
        "#generate train\n",
        "for group_name, df_group in train.groupby(\"machineID\"):\n",
        "  # print(\"user name\",group_name)\n",
        "  leng = len(df_group)\n",
        "  start_ids = np.arange(0,leng-input_length+1,input_length)\n",
        "  for id in start_ids:\n",
        "    X = df_group.iloc[id:id+input_length,2:-1].values.astype(np.float32)\n",
        "    y = df_group.iloc[id:id+input_length,-1]\n",
        "    label = y.max()\n",
        "    x_train.append(X)\n",
        "    y_train.append(label)\n",
        "    #generate more data\n",
        "    if label > 0 and leng- id > input_length and id:\n",
        "      pos_ids = hours[(y > 0).values]\n",
        "      for sample_id in np.random.randint(pos_ids.min()-Q3,pos_ids.max()-Q1+1,n_upsampling):\n",
        "        X = df_group.iloc[id+sample_id:id+sample_id+input_length,2:-1].values.astype(np.float32)\n",
        "        y = df_group.iloc[id+sample_id:id+sample_id+input_length,-1]\n",
        "        x_train.append(X)\n",
        "        y_train.append(y.max())\n",
        "  for id in np.random.randint(Q1,Q3+1,len(start_ids)-1):\n",
        "    X = df_group.iloc[id:id+input_length,2:-1].values.astype(np.float32)\n",
        "    y = df_group.iloc[id:id+input_length,-1].max()\n",
        "    if y > 0:\n",
        "      continue\n",
        "    x_train.append(X)\n",
        "    y_train.append(y)\n",
        "\n",
        "#generate test\n",
        "for group_name, df_group in test.groupby(\"machineID\"):\n",
        "  leng = len(df_group)\n",
        "  start_ids = np.arange(0,leng-input_length+1,input_length)\n",
        "  # slide_ids = np.arange(Q2,leng-input_length+1,input_length)\n",
        "  # start_ids = list(start_ids) + list(slide_ids)\n",
        "  for id in start_ids:\n",
        "    X = df_group.iloc[id:id+input_length,2:-1].values.astype(np.float32)\n",
        "    y = df_group.iloc[id:id+input_length,-1].max()\n",
        "    x_test.append(X)\n",
        "    y_test.append(y)"
      ],
      "metadata": {
        "id": "mjiaqtI5dHGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to 1 hot\n",
        "x_test = np.array(x_test)\n",
        "y_test_ = np.array(y_test)\n",
        "y_test = np.zeros((y_test_.size, 2))\n",
        "y_test[np.arange(y_test_.size), y_test_] = 1\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train_ = np.array(y_train)\n",
        "y_train = np.zeros((y_train_.size, 2))\n",
        "y_train[np.arange(y_train_.size), y_train_] = 1"
      ],
      "metadata": {
        "id": "Ml6cAP06HkC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show label distribution\n",
        "len(y_train),len(y_test), np.unique(y_train.argmax(1),return_counts=True), np.unique(y_test.argmax(1),return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DEZxag8hT7e",
        "outputId": "36e78a6f-be88-4647-a84c-7984396b3ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55420,\n",
              " 7300,\n",
              " (array([0, 1]), array([52007,  3413])),\n",
              " (array([0, 1]), array([7167,  133])))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
        "where `sequence length` is the number of time steps and `features` is each input\n",
        "timeseries.\n",
        "\n",
        "You can replace your classification RNN layers with this one: the\n",
        "inputs are fully compatible!"
      ],
      "metadata": {
        "id": "JqyWWon1DQp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We include residual connections, layer normalization, and dropout.\n",
        "The resulting layer can be stacked multiple times.\n",
        "\n",
        "The projection layers are implemented through `keras.layers.Conv1D`."
      ],
      "metadata": {
        "id": "TYqcv_HYDQp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "MrjiGB2IDQqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "EGyPKoJIDQqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate"
      ],
      "metadata": {
        "id": "kaxXpObaDQqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "print(input_shape)\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=128,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[64],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[tfa.metrics.F1Score(num_classes=n_classes),'accuracy'],\n",
        ")\n",
        "model.summary()\n",
        "checkpoint_path = \"/content/drive/MyDrive/aitomatic/training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "callbacks = [cp_callback]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data= (x_test,y_test),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 20)\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 24, 20)]     0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 24, 20)      40          ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 24, 20)      42516       ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 24, 20)       0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 24, 20)      0           ['dropout_2[0][0]',              \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 24, 4)        84          ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 24, 4)        0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 24, 20)       100         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 24, 20)      0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 24, 20)      42516       ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 24, 20)       0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 24, 20)      0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 24, 4)        84          ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 24, 4)        0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 24, 20)       100         ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 24, 20)      0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 24, 20)      42516       ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 24, 20)       0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 24, 20)      0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 24, 4)        84          ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 24, 4)        0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 24, 20)       100         ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 24, 20)      0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 24, 20)      42516       ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 24, 20)       0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 24, 20)      0           ['dropout_8[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 24, 20)      40          ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 24, 4)        84          ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 24, 4)        0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 24, 20)       100         ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 24, 20)      0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 24)          0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           1600        ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 64)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 5)            325         ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 173,045\n",
            "Trainable params: 173,045\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 9.0631 - f1_score: 0.1779 - accuracy: 0.6651\n",
            "Epoch 1: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 39s 23ms/step - loss: 9.0631 - f1_score: 0.1779 - accuracy: 0.6651 - val_loss: 0.2696 - val_f1_score: 0.2073 - val_accuracy: 0.9587\n",
            "Epoch 2/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.9628 - f1_score: 0.2089 - accuracy: 0.8464\n",
            "Epoch 2: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 21ms/step - loss: 0.9620 - f1_score: 0.2090 - accuracy: 0.8464 - val_loss: 0.1826 - val_f1_score: 0.2161 - val_accuracy: 0.9724\n",
            "Epoch 3/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.7299 - f1_score: 0.2151 - accuracy: 0.8666\n",
            "Epoch 3: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.7297 - f1_score: 0.2151 - accuracy: 0.8666 - val_loss: 0.1465 - val_f1_score: 0.2147 - val_accuracy: 0.9808\n",
            "Epoch 4/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.6056 - f1_score: 0.2195 - accuracy: 0.8929\n",
            "Epoch 4: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.6056 - f1_score: 0.2195 - accuracy: 0.8929 - val_loss: 0.1410 - val_f1_score: 0.2260 - val_accuracy: 0.9808\n",
            "Epoch 5/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.5368 - f1_score: 0.2236 - accuracy: 0.9042\n",
            "Epoch 5: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 24ms/step - loss: 0.5368 - f1_score: 0.2236 - accuracy: 0.9042 - val_loss: 0.1421 - val_f1_score: 0.2281 - val_accuracy: 0.9807\n",
            "Epoch 6/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.4859 - f1_score: 0.2306 - accuracy: 0.9149\n",
            "Epoch 6: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.4857 - f1_score: 0.2305 - accuracy: 0.9149 - val_loss: 0.1502 - val_f1_score: 0.2142 - val_accuracy: 0.9806\n",
            "Epoch 7/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.4464 - f1_score: 0.2243 - accuracy: 0.9210\n",
            "Epoch 7: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.4460 - f1_score: 0.2242 - accuracy: 0.9211 - val_loss: 0.1639 - val_f1_score: 0.2081 - val_accuracy: 0.9807\n",
            "Epoch 8/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.4158 - f1_score: 0.2193 - accuracy: 0.9293\n",
            "Epoch 8: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.4158 - f1_score: 0.2193 - accuracy: 0.9293 - val_loss: 0.1784 - val_f1_score: 0.2056 - val_accuracy: 0.9814\n",
            "Epoch 9/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3817 - f1_score: 0.2056 - accuracy: 0.9348\n",
            "Epoch 9: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 21ms/step - loss: 0.3817 - f1_score: 0.2056 - accuracy: 0.9348 - val_loss: 0.1800 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 10/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3617 - f1_score: 0.1943 - accuracy: 0.9377\n",
            "Epoch 10: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3617 - f1_score: 0.1943 - accuracy: 0.9377 - val_loss: 0.1894 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 11/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3522 - f1_score: 0.1948 - accuracy: 0.9382\n",
            "Epoch 11: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.3522 - f1_score: 0.1948 - accuracy: 0.9382 - val_loss: 0.1871 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 12/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3423 - f1_score: 0.1936 - accuracy: 0.9382\n",
            "Epoch 12: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3421 - f1_score: 0.1936 - accuracy: 0.9382 - val_loss: 0.1876 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 13/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3374 - f1_score: 0.1936 - accuracy: 0.9383\n",
            "Epoch 13: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.3374 - f1_score: 0.1936 - accuracy: 0.9383 - val_loss: 0.1890 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 14/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3366 - f1_score: 0.1955 - accuracy: 0.9384\n",
            "Epoch 14: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 21ms/step - loss: 0.3366 - f1_score: 0.1955 - accuracy: 0.9384 - val_loss: 0.1783 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 15/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.3317 - f1_score: 0.1940 - accuracy: 0.9383\n",
            "Epoch 15: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3318 - f1_score: 0.1940 - accuracy: 0.9383 - val_loss: 0.1776 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 16/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3253 - f1_score: 0.1968 - accuracy: 0.9385\n",
            "Epoch 16: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.3253 - f1_score: 0.1968 - accuracy: 0.9385 - val_loss: 0.1787 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 17/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3233 - f1_score: 0.1968 - accuracy: 0.9385\n",
            "Epoch 17: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3233 - f1_score: 0.1968 - accuracy: 0.9385 - val_loss: 0.1782 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 18/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3194 - f1_score: 0.1972 - accuracy: 0.9386\n",
            "Epoch 18: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3194 - f1_score: 0.1972 - accuracy: 0.9386 - val_loss: 0.1718 - val_f1_score: 0.2023 - val_accuracy: 0.9819\n",
            "Epoch 19/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3158 - f1_score: 0.1999 - accuracy: 0.9384\n",
            "Epoch 19: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.3158 - f1_score: 0.1999 - accuracy: 0.9384 - val_loss: 0.1808 - val_f1_score: 0.1982 - val_accuracy: 0.9818\n",
            "Epoch 20/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3153 - f1_score: 0.2002 - accuracy: 0.9385\n",
            "Epoch 20: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3151 - f1_score: 0.2002 - accuracy: 0.9385 - val_loss: 0.1613 - val_f1_score: 0.2023 - val_accuracy: 0.9819\n",
            "Epoch 21/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3120 - f1_score: 0.2007 - accuracy: 0.9385\n",
            "Epoch 21: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.3120 - f1_score: 0.2007 - accuracy: 0.9385 - val_loss: 0.1588 - val_f1_score: 0.2061 - val_accuracy: 0.9818\n",
            "Epoch 22/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3101 - f1_score: 0.2035 - accuracy: 0.9385\n",
            "Epoch 22: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.3101 - f1_score: 0.2035 - accuracy: 0.9385 - val_loss: 0.1699 - val_f1_score: 0.2130 - val_accuracy: 0.9816\n",
            "Epoch 23/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3061 - f1_score: 0.2022 - accuracy: 0.9384\n",
            "Epoch 23: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.3062 - f1_score: 0.2021 - accuracy: 0.9384 - val_loss: 0.1596 - val_f1_score: 0.2059 - val_accuracy: 0.9817\n",
            "Epoch 24/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.3051 - f1_score: 0.2095 - accuracy: 0.9386\n",
            "Epoch 24: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3050 - f1_score: 0.2095 - accuracy: 0.9387 - val_loss: 0.1603 - val_f1_score: 0.2060 - val_accuracy: 0.9817\n",
            "Epoch 25/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.3059 - f1_score: 0.2066 - accuracy: 0.9387\n",
            "Epoch 25: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3060 - f1_score: 0.2066 - accuracy: 0.9387 - val_loss: 0.1683 - val_f1_score: 0.2128 - val_accuracy: 0.9815\n",
            "Epoch 26/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.3034 - f1_score: 0.2054 - accuracy: 0.9382\n",
            "Epoch 26: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.3031 - f1_score: 0.2054 - accuracy: 0.9383 - val_loss: 0.1519 - val_f1_score: 0.2097 - val_accuracy: 0.9817\n",
            "Epoch 27/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.3013 - f1_score: 0.2107 - accuracy: 0.9387\n",
            "Epoch 27: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3010 - f1_score: 0.2107 - accuracy: 0.9387 - val_loss: 0.1552 - val_f1_score: 0.2060 - val_accuracy: 0.9817\n",
            "Epoch 28/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.3004 - f1_score: 0.2109 - accuracy: 0.9388\n",
            "Epoch 28: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.3004 - f1_score: 0.2109 - accuracy: 0.9388 - val_loss: 0.1500 - val_f1_score: 0.2196 - val_accuracy: 0.9816\n",
            "Epoch 29/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2969 - f1_score: 0.2132 - accuracy: 0.9387\n",
            "Epoch 29: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2969 - f1_score: 0.2132 - accuracy: 0.9387 - val_loss: 0.1472 - val_f1_score: 0.2021 - val_accuracy: 0.9817\n",
            "Epoch 30/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2969 - f1_score: 0.2100 - accuracy: 0.9384\n",
            "Epoch 30: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2968 - f1_score: 0.2100 - accuracy: 0.9384 - val_loss: 0.1561 - val_f1_score: 0.2060 - val_accuracy: 0.9816\n",
            "Epoch 31/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2963 - f1_score: 0.2120 - accuracy: 0.9386\n",
            "Epoch 31: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2963 - f1_score: 0.2120 - accuracy: 0.9386 - val_loss: 0.1439 - val_f1_score: 0.2059 - val_accuracy: 0.9816\n",
            "Epoch 32/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2931 - f1_score: 0.2134 - accuracy: 0.9385\n",
            "Epoch 32: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2931 - f1_score: 0.2134 - accuracy: 0.9385 - val_loss: 0.1482 - val_f1_score: 0.2022 - val_accuracy: 0.9816\n",
            "Epoch 33/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2926 - f1_score: 0.2106 - accuracy: 0.9386\n",
            "Epoch 33: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2926 - f1_score: 0.2105 - accuracy: 0.9387 - val_loss: 0.1401 - val_f1_score: 0.2059 - val_accuracy: 0.9815\n",
            "Epoch 34/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2922 - f1_score: 0.2093 - accuracy: 0.9382\n",
            "Epoch 34: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2922 - f1_score: 0.2093 - accuracy: 0.9382 - val_loss: 0.1496 - val_f1_score: 0.2059 - val_accuracy: 0.9815\n",
            "Epoch 35/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2887 - f1_score: 0.2143 - accuracy: 0.9385\n",
            "Epoch 35: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2885 - f1_score: 0.2143 - accuracy: 0.9386 - val_loss: 0.1393 - val_f1_score: 0.2170 - val_accuracy: 0.9819\n",
            "Epoch 36/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2854 - f1_score: 0.2129 - accuracy: 0.9384\n",
            "Epoch 36: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.2854 - f1_score: 0.2129 - accuracy: 0.9384 - val_loss: 0.1381 - val_f1_score: 0.2059 - val_accuracy: 0.9815\n",
            "Epoch 37/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2878 - f1_score: 0.2095 - accuracy: 0.9384\n",
            "Epoch 37: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2879 - f1_score: 0.2094 - accuracy: 0.9384 - val_loss: 0.1401 - val_f1_score: 0.2059 - val_accuracy: 0.9815\n",
            "Epoch 38/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2855 - f1_score: 0.2103 - accuracy: 0.9386\n",
            "Epoch 38: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.2856 - f1_score: 0.2103 - accuracy: 0.9385 - val_loss: 0.1365 - val_f1_score: 0.2059 - val_accuracy: 0.9816\n",
            "Epoch 39/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2837 - f1_score: 0.2135 - accuracy: 0.9389\n",
            "Epoch 39: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2837 - f1_score: 0.2135 - accuracy: 0.9389 - val_loss: 0.1397 - val_f1_score: 0.2097 - val_accuracy: 0.9817\n",
            "Epoch 40/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2856 - f1_score: 0.2128 - accuracy: 0.9385\n",
            "Epoch 40: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2856 - f1_score: 0.2128 - accuracy: 0.9385 - val_loss: 0.1300 - val_f1_score: 0.2059 - val_accuracy: 0.9817\n",
            "Epoch 41/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2829 - f1_score: 0.2103 - accuracy: 0.9387\n",
            "Epoch 41: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2829 - f1_score: 0.2103 - accuracy: 0.9387 - val_loss: 0.1417 - val_f1_score: 0.2059 - val_accuracy: 0.9816\n",
            "Epoch 42/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2807 - f1_score: 0.2135 - accuracy: 0.9388\n",
            "Epoch 42: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2804 - f1_score: 0.2135 - accuracy: 0.9389 - val_loss: 0.1481 - val_f1_score: 0.2059 - val_accuracy: 0.9814\n",
            "Epoch 43/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2799 - f1_score: 0.2109 - accuracy: 0.9384\n",
            "Epoch 43: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2800 - f1_score: 0.2109 - accuracy: 0.9384 - val_loss: 0.1344 - val_f1_score: 0.2059 - val_accuracy: 0.9817\n",
            "Epoch 44/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2800 - f1_score: 0.2107 - accuracy: 0.9387\n",
            "Epoch 44: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2802 - f1_score: 0.2107 - accuracy: 0.9387 - val_loss: 0.1320 - val_f1_score: 0.2059 - val_accuracy: 0.9816\n",
            "Epoch 45/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2755 - f1_score: 0.2140 - accuracy: 0.9389\n",
            "Epoch 45: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2755 - f1_score: 0.2140 - accuracy: 0.9389 - val_loss: 0.1364 - val_f1_score: 0.2020 - val_accuracy: 0.9813\n",
            "Epoch 46/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2769 - f1_score: 0.2107 - accuracy: 0.9387\n",
            "Epoch 46: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.2769 - f1_score: 0.2107 - accuracy: 0.9387 - val_loss: 0.1297 - val_f1_score: 0.2096 - val_accuracy: 0.9817\n",
            "Epoch 47/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2769 - f1_score: 0.2126 - accuracy: 0.9385\n",
            "Epoch 47: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2767 - f1_score: 0.2125 - accuracy: 0.9386 - val_loss: 0.1347 - val_f1_score: 0.1981 - val_accuracy: 0.9817\n",
            "Epoch 48/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2751 - f1_score: 0.2082 - accuracy: 0.9385\n",
            "Epoch 48: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2752 - f1_score: 0.2082 - accuracy: 0.9385 - val_loss: 0.1350 - val_f1_score: 0.2080 - val_accuracy: 0.9815\n",
            "Epoch 49/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2723 - f1_score: 0.2167 - accuracy: 0.9390\n",
            "Epoch 49: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2723 - f1_score: 0.2167 - accuracy: 0.9390 - val_loss: 0.1381 - val_f1_score: 0.2039 - val_accuracy: 0.9815\n",
            "Epoch 50/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2731 - f1_score: 0.2086 - accuracy: 0.9386\n",
            "Epoch 50: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2732 - f1_score: 0.2086 - accuracy: 0.9385 - val_loss: 0.1302 - val_f1_score: 0.2096 - val_accuracy: 0.9817\n",
            "Epoch 51/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2727 - f1_score: 0.2114 - accuracy: 0.9386\n",
            "Epoch 51: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2731 - f1_score: 0.2117 - accuracy: 0.9385 - val_loss: 0.1251 - val_f1_score: 0.2078 - val_accuracy: 0.9814\n",
            "Epoch 52/200\n",
            "864/866 [============================>.] - ETA: 0s - loss: 0.2727 - f1_score: 0.2147 - accuracy: 0.9389\n",
            "Epoch 52: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2730 - f1_score: 0.2146 - accuracy: 0.9388 - val_loss: 0.1293 - val_f1_score: 0.2059 - val_accuracy: 0.9817\n",
            "Epoch 53/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2731 - f1_score: 0.2094 - accuracy: 0.9387\n",
            "Epoch 53: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 22s 25ms/step - loss: 0.2731 - f1_score: 0.2094 - accuracy: 0.9387 - val_loss: 0.1277 - val_f1_score: 0.2021 - val_accuracy: 0.9815\n",
            "Epoch 54/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2710 - f1_score: 0.2123 - accuracy: 0.9387\n",
            "Epoch 54: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.2710 - f1_score: 0.2123 - accuracy: 0.9388 - val_loss: 0.1280 - val_f1_score: 0.2082 - val_accuracy: 0.9817\n",
            "Epoch 55/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2700 - f1_score: 0.2140 - accuracy: 0.9387\n",
            "Epoch 55: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 23s 26ms/step - loss: 0.2702 - f1_score: 0.2140 - accuracy: 0.9387 - val_loss: 0.1269 - val_f1_score: 0.2021 - val_accuracy: 0.9816\n",
            "Epoch 56/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2707 - f1_score: 0.2131 - accuracy: 0.9388\n",
            "Epoch 56: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2707 - f1_score: 0.2131 - accuracy: 0.9388 - val_loss: 0.1276 - val_f1_score: 0.2081 - val_accuracy: 0.9817\n",
            "Epoch 57/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2683 - f1_score: 0.2177 - accuracy: 0.9390\n",
            "Epoch 57: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2683 - f1_score: 0.2177 - accuracy: 0.9390 - val_loss: 0.1281 - val_f1_score: 0.2079 - val_accuracy: 0.9814\n",
            "Epoch 58/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2681 - f1_score: 0.2198 - accuracy: 0.9389\n",
            "Epoch 58: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2682 - f1_score: 0.2197 - accuracy: 0.9389 - val_loss: 0.1274 - val_f1_score: 0.2059 - val_accuracy: 0.9817\n",
            "Epoch 59/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2670 - f1_score: 0.2173 - accuracy: 0.9390\n",
            "Epoch 59: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 22ms/step - loss: 0.2672 - f1_score: 0.2173 - accuracy: 0.9390 - val_loss: 0.1227 - val_f1_score: 0.2080 - val_accuracy: 0.9815\n",
            "Epoch 60/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2679 - f1_score: 0.2195 - accuracy: 0.9390\n",
            "Epoch 60: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 20s 23ms/step - loss: 0.2679 - f1_score: 0.2195 - accuracy: 0.9390 - val_loss: 0.1333 - val_f1_score: 0.2156 - val_accuracy: 0.9817\n",
            "Epoch 61/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2678 - f1_score: 0.2218 - accuracy: 0.9393\n",
            "Epoch 61: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 19s 23ms/step - loss: 0.2678 - f1_score: 0.2218 - accuracy: 0.9393 - val_loss: 0.1291 - val_f1_score: 0.2154 - val_accuracy: 0.9814\n",
            "Epoch 62/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2656 - f1_score: 0.2240 - accuracy: 0.9392\n",
            "Epoch 62: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 21s 24ms/step - loss: 0.2656 - f1_score: 0.2240 - accuracy: 0.9392 - val_loss: 0.1253 - val_f1_score: 0.2170 - val_accuracy: 0.9814\n",
            "Epoch 63/200\n",
            "866/866 [==============================] - ETA: 0s - loss: 0.2669 - f1_score: 0.2260 - accuracy: 0.9391\n",
            "Epoch 63: saving model to training_1/cp.ckpt\n",
            "866/866 [==============================] - 22s 25ms/step - loss: 0.2669 - f1_score: 0.2260 - accuracy: 0.9391 - val_loss: 0.1270 - val_f1_score: 0.2120 - val_accuracy: 0.9817\n",
            "Epoch 64/200\n",
            "865/866 [============================>.] - ETA: 0s - loss: 0.2670 - f1_score: 0.2222 - accuracy: 0.9391\n",
            "Epoch 64: saving model to training_1/cp.ckpt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a29a39889c77>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m                         )\n\u001b[1;32m   1562\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m                         self.model.save_weights(\n\u001b[0m\u001b[1;32m   1564\u001b[0m                             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m   2896\u001b[0m                 \u001b[0mHDF5\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m         \"\"\"\n\u001b[0;32m-> 2898\u001b[0;31m         saving_api.save_weights(\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0msaving_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         legacy_sm_saving_lib.save_weights(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;31m# Call `get_session` to initialize any uninitialized variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Record this checkpoint so it's visible from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m   2254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m       \u001b[0mfile_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_async_checkpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self, file_prefix, options, write_done_callback)\u001b[0m\n\u001b[1;32m   2289\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2290\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2291\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2292\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_file_name_tensor_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1302\u001b[0m       \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0m\u001b[1;32m   1305\u001b[0m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       saver = functional_saver.MultiDeviceSaver(serialized_tensors,\n\u001b[1;32m   1241\u001b[0m                                                 registered_savers)\n\u001b[0;32m-> 1242\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    405\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mslice_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m           \u001b[0;31m# A tensor value of `None` indicates that this SaveableObject gets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0;31m# recorded in the object graph, but that no value is saved in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saving/saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m           \u001b[0;31m# A SaveSpec tensor value of `None` indicates that the variable is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m           \u001b[0;31m# uninitialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mis_initialized\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m     \"\"\"\n\u001b[0;32m--> 890\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_is_initialized_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mvar_is_initialized_op\u001b[0;34m(resource, name)\u001b[0m\n\u001b[1;32m   1316\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1319\u001b[0m         _ctx, \"VarIsInitializedOp\", name, resource)\n\u001b[1;32m   1320\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "id": "gJY5EifgDQqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5deb9be-01a7-42cb-a9cd-452d35ab616e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = tfa.metrics.F1Score(num_classes=n_classes)\n",
        "metric.update_state(y_test, model.predict(x_test))\n",
        "result = metric.result()\n",
        "result.numpy()\n"
      ],
      "metadata": {
        "id": "TPMc-AZ_RNWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca862b0-c92a-458c-ce01-cbdbcbf87dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "454/454 [==============================] - 3s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9907401 , 0.        , 0.05769231, 0.        , 0.02985075],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=x_train.shape[1:], name='input')\n",
        "\n",
        "# x1 = layers.LSTM(units=50,return_sequences=True)(inputs)\n",
        "# x1 = layers.Dropout(0.2)(x1)\n",
        "# x1 = layers.LSTM(units=50,return_sequences=False)(inputs)\n",
        "# x1 = layers.Dropout(0.2)(x1)\n",
        "\n",
        "# outputs = layers.Dense(n_classes, activation=\"softmax\")(x1)\n",
        "x1 = layers.Bidirectional(layers.LSTM(units=50,return_sequences=False))(inputs)\n",
        "x1 = layers.Dropout(0.2)(x1)\n",
        "x2 = layers.Bidirectional(layers.LSTM(units=50,return_sequences=False))(inputs)\n",
        "x2 = layers.Dropout(0.2)(x2)\n",
        "# x3 = layers.Bidirectional(layers.LSTM(units=50,return_sequences=False))(inputs)\n",
        "# x3 = layers.Dropout(0.2)(x3)\n",
        "outputs = layers.Dense(n_classes, activation=\"softmax\")(x2)"
      ],
      "metadata": {
        "id": "vMjViR0qujm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# model.save_weights('my_checkpoint')\n",
        "checkpoint_path = \"/content/drive/MyDrive/aitomatic/training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,ave_weights_only=True,save_best_only=True,verbose=1)\n",
        "callbacks = [cp_callback]\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    metrics=[tfa.metrics.F1Score(num_classes=n_classes)],\n",
        ")\n",
        "model.summary()\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data= (x_test,y_test),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nwRQrVVcuzAP",
        "outputId": "527ee6da-6b71-4678-f807-6fcb34d382be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 24, 14)]          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100)              26000     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,505\n",
            "Trainable params: 26,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f2c230441548>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 2) and (None, 5) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = tfa.metrics.F1Score(num_classes=n_classes)\n",
        "metric.update_state(y_test, model.predict(x_test))\n",
        "result = metric.result()\n",
        "f1 = result.numpy()\n",
        "print(f1, f1.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqEpJSU3FcqB",
        "outputId": "02caaed1-90ad-4008-dec4-9b867f64f170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "454/454 [==============================] - 3s 4ms/step\n",
            "[0.99175483 0.5662651  0.70119524 0.77477473 0.55399054] 0.7175961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  inputs = layers.Input(shape=(24,20), name='input')\n",
        "  x1 = layers.Bidirectional(layers.LSTM(units=50,return_sequences=False))(inputs)\n",
        "  x1 = layers.Dropout(0.2)(x1)\n",
        "  x2 = layers.Bidirectional(layers.LSTM(units=50,return_sequences=False))(inputs)\n",
        "  x2 = layers.Dropout(0.2)(x2)\n",
        "  outputs = layers.Dense(n_classes, activation=\"softmax\")(x2)\n",
        "  return keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "model = create_model()\n",
        "model.load_weights(\"/content/drive/MyDrive/training_1/cp.ckpt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb5gXDsE9UFJ",
        "outputId": "5b895e6e-9f4d-4aaf-8c4f-e1ab81eddc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7bb509731900>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8f7WLejAHDQ",
        "outputId": "c1c0741b-3edd-4a0e-fefe-d33e8bc071ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration',\n",
              "       'errorID_error1', 'errorID_error2', 'errorID_error3', 'errorID_error4',\n",
              "       'errorID_error5', 'comp_comp1', 'comp_comp2', 'comp_comp3',\n",
              "       'comp_comp4', 'age', 'model_model1', 'model_model2', 'model_model3',\n",
              "       'model_model4', 'hours', 'failure'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.iloc[0].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2UaTwqoBYTI",
        "outputId": "26f82b90-f9de-433f-fd15-e229129d643c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Timestamp('2015-01-01 06:00:00'), 1, 176.217853015625,\n",
              "       418.504078221616, 113.077935462083, 45.0876857639276, 0.0, 0.0,\n",
              "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18, 0, 0, 1, 0, 0.25, 0],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features[\"failure\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpb82WdCB9tJ",
        "outputId": "96d3f251-5f7c-416d-8ced-3965c8db57bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    876087\n",
              "2       386\n",
              "1       291\n",
              "4       255\n",
              "3       190\n",
              "Name: failure, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}